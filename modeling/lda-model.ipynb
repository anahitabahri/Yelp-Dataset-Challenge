{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../yelp-data/new_data/final_data/manip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=False,\n",
    "                     stop_words='english',\n",
    "                     min_df=3)\n",
    "\n",
    "docs = cv.fit_transform(data.text.dropna())\n",
    "\n",
    "# Build a mapping of numerical ID to word\n",
    "id2word = dict(enumerate(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.matutils import Sparse2Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert our word-matrix into gensim's format\n",
    "corpus = Sparse2Corpus(docs, documents_columns = False)\n",
    "\n",
    "# fit an LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=15)\n",
    "\n",
    "# need to explicitly specify the number of topics we want the model to uncover\n",
    "# num_topics = 10\n",
    "# lda_model = LdaModel(corpus=corpus, \n",
    "#                     id2word=dict(enumerate(vectorizer.get_feature_names())), \n",
    "#                     num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we learn reasonable topics?  \n",
    "Do the words that make up a topic make sense?  \n",
    "Is this topic helpful towards our goal?  \n",
    "We can evaluate fit by viewing the top words in each topic. Some topics will be clearer than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "(0, u'0.016*\"like\" + 0.014*\"place\" + 0.011*\"old\" + 0.008*\"new\" + 0.007*\"just\" + 0.007*\"don\" + 0.006*\"ve\" + 0.005*\"know\" + 0.005*\"steak\" + 0.005*\"feel\"')\n",
      "\n",
      "Topic: 1\n",
      "(1, u'0.034*\"fries\" + 0.027*\"cheese\" + 0.026*\"burger\" + 0.022*\"steak\" + 0.022*\"sandwich\" + 0.018*\"good\" + 0.013*\"philly\" + 0.013*\"place\" + 0.009*\"like\" + 0.009*\"burgers\"')\n",
      "\n",
      "Topic: 2\n",
      "(2, u'0.039*\"chicken\" + 0.032*\"pork\" + 0.029*\"fried\" + 0.018*\"ribs\" + 0.015*\"sauce\" + 0.015*\"bbq\" + 0.014*\"beef\" + 0.010*\"belly\" + 0.009*\"sweet\" + 0.009*\"rolls\"')\n",
      "\n",
      "Topic: 3\n",
      "(3, u'0.028*\"breakfast\" + 0.027*\"eggs\" + 0.023*\"sushi\" + 0.022*\"steak\" + 0.018*\"fried\" + 0.013*\"chicken\" + 0.013*\"brunch\" + 0.012*\"good\" + 0.011*\"place\" + 0.010*\"roll\"')\n",
      "\n",
      "Topic: 4\n",
      "(4, u'0.043*\"great\" + 0.039*\"food\" + 0.028*\"place\" + 0.026*\"service\" + 0.020*\"good\" + 0.014*\"steak\" + 0.011*\"staff\" + 0.011*\"amazing\" + 0.011*\"restaurant\" + 0.010*\"time\"')\n",
      "\n",
      "Topic: 5\n",
      "(5, u'0.017*\"food\" + 0.012*\"table\" + 0.011*\"time\" + 0.011*\"minutes\" + 0.010*\"came\" + 0.009*\"service\" + 0.009*\"asked\" + 0.009*\"order\" + 0.009*\"just\" + 0.008*\"server\"')\n",
      "\n",
      "Topic: 6\n",
      "(6, u'0.020*\"ordered\" + 0.018*\"steak\" + 0.013*\"medium\" + 0.012*\"came\" + 0.012*\"rib\" + 0.011*\"rare\" + 0.010*\"dinner\" + 0.010*\"cooked\" + 0.008*\"server\" + 0.008*\"meal\"')\n",
      "\n",
      "Topic: 7\n",
      "(7, u'0.039*\"vegas\" + 0.026*\"meat\" + 0.022*\"las\" + 0.014*\"restaurant\" + 0.010*\"experience\" + 0.009*\"steakhouse\" + 0.008*\"beef\" + 0.008*\"dining\" + 0.007*\"meats\" + 0.007*\"restaurants\"')\n",
      "\n",
      "Topic: 8\n",
      "(8, u'0.013*\"die\" + 0.013*\"und\" + 0.013*\"room\" + 0.009*\"das\" + 0.007*\"hotel\" + 0.007*\"war\" + 0.006*\"es\" + 0.005*\"auch\" + 0.005*\"mit\" + 0.005*\"stay\"')\n",
      "\n",
      "Topic: 9\n",
      "(9, u'0.021*\"beer\" + 0.014*\"buffet\" + 0.013*\"salad\" + 0.013*\"selection\" + 0.010*\"bar\" + 0.010*\"steak\" + 0.009*\"good\" + 0.008*\"pizza\" + 0.007*\"beers\" + 0.007*\"lunch\"')\n",
      "\n",
      "Topic: 10\n",
      "(10, u'0.012*\"menu\" + 0.010*\"dish\" + 0.009*\"sauce\" + 0.008*\"delicious\" + 0.007*\"cheese\" + 0.007*\"dessert\" + 0.007*\"served\" + 0.006*\"cream\" + 0.006*\"chocolate\" + 0.006*\"bread\"')\n",
      "\n",
      "Topic: 11\n",
      "(11, u'0.020*\"great\" + 0.019*\"steak\" + 0.017*\"amazing\" + 0.016*\"service\" + 0.016*\"best\" + 0.013*\"lobster\" + 0.012*\"delicious\" + 0.012*\"filet\" + 0.011*\"food\" + 0.010*\"excellent\"')\n",
      "\n",
      "Topic: 12\n",
      "(12, u'0.029*\"steak\" + 0.025*\"tacos\" + 0.018*\"chicken\" + 0.017*\"rice\" + 0.014*\"food\" + 0.012*\"taco\" + 0.011*\"burrito\" + 0.011*\"good\" + 0.010*\"mexican\" + 0.010*\"salsa\"')\n",
      "\n",
      "Topic: 13\n",
      "(13, u'0.045*\"pho\" + 0.028*\"fajitas\" + 0.026*\"chips\" + 0.026*\"nachos\" + 0.022*\"la\" + 0.018*\"steak\" + 0.012*\"pour\" + 0.011*\"com\" + 0.010*\"que\" + 0.009*\"margarita\"')\n",
      "\n",
      "Topic: 14\n",
      "(14, u'0.037*\"steak\" + 0.032*\"good\" + 0.020*\"food\" + 0.016*\"ordered\" + 0.016*\"like\" + 0.016*\"just\" + 0.013*\"place\" + 0.013*\"really\" + 0.013*\"salad\" + 0.011*\"got\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_topics = 15\n",
    "num_words_per_topic = 10\n",
    "for ti, topic in enumerate(lda_model.show_topics(num_topics = num_topics, num_words = num_words_per_topic)):\n",
    "    print \"Topic: %d\" % (ti)\n",
    "    print topic\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/RaRe-Technologies/gensim/issues/484"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fewer topics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert our word-matrix into gensim's format\n",
    "corpus = Sparse2Corpus(docs, documents_columns = False)\n",
    "\n",
    "# fit an LDA model\n",
    "lda = LdaModel(corpus=corpus, id2word=id2word, num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "(0, u'0.019*\"great\" + 0.017*\"steak\" + 0.014*\"service\" + 0.012*\"amazing\" + 0.012*\"food\" + 0.011*\"best\" + 0.009*\"delicious\" + 0.009*\"restaurant\" + 0.008*\"good\" + 0.008*\"excellent\"')\n",
      "\n",
      "Topic: 1\n",
      "(1, u'0.014*\"food\" + 0.013*\"ordered\" + 0.012*\"came\" + 0.012*\"steak\" + 0.010*\"table\" + 0.009*\"time\" + 0.009*\"server\" + 0.009*\"service\" + 0.009*\"got\" + 0.008*\"just\"')\n",
      "\n",
      "Topic: 2\n",
      "(2, u'0.033*\"tacos\" + 0.017*\"steak\" + 0.016*\"taco\" + 0.015*\"burrito\" + 0.014*\"mexican\" + 0.013*\"salsa\" + 0.012*\"chips\" + 0.007*\"beans\" + 0.007*\"die\" + 0.007*\"chicken\"')\n",
      "\n",
      "Topic: 3\n",
      "(3, u'0.020*\"steak\" + 0.019*\"good\" + 0.013*\"chicken\" + 0.011*\"cheese\" + 0.010*\"like\" + 0.009*\"ordered\" + 0.009*\"fries\" + 0.008*\"sauce\" + 0.008*\"just\" + 0.007*\"really\"')\n",
      "\n",
      "Topic: 4\n",
      "(4, u'0.024*\"food\" + 0.022*\"place\" + 0.017*\"great\" + 0.014*\"good\" + 0.011*\"steak\" + 0.011*\"service\" + 0.008*\"like\" + 0.008*\"time\" + 0.008*\"bar\" + 0.007*\"just\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_topics = 5\n",
    "num_words_per_topic = 10\n",
    "for ti, topic in enumerate(lda.show_topics(num_topics = num_topics, num_words = num_words_per_topic)):\n",
    "    print \"Topic: %d\" % (ti)\n",
    "    print topic\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'token2id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4aaec4564d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/pyLDAvis/gensim.pyc\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/pyLDAvis/gensim.pyc\u001b[0m in \u001b[0;36m_extract_data\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mcorpus_csc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m    \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m    \u001b[0;31m# TODO: add the hyperparam to smooth it out? no beta in online LDA impl.. hmm..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m    \u001b[0;31m# for now, I'll just make sure we don't ever get zeros...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'token2id'"
     ]
    }
   ],
   "source": [
    "vis_data = gensimvis.prepare(lda, corpus, text)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
